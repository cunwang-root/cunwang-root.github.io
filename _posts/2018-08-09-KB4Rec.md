---
layout: post
title: "KB4Rec"
date: 2018-12-23
categories: [Machinelearning]
tags: [knowledge base, recommender system, deep learning]
mathjax: true
---

## End-To-End Memory Networks

A novel recurrent neural network (RNN) architecture where the recurrence reads from a possibly large external memory multiple times before outputting
a symbol. 

The key concept of multiple computational hops yields improved results.

1. single layer case

## Key-Value Memory Networks for Directly Reading Documents

Knowledge Bases (KBs) have intrinsic limitations such as their inevitable incompleteness and fixed schemas that cannot support alarietie
To bridge the gap between using a KB and reading documents directly, the Key-Value Memory Network (KV-MemNN) is proposed, which can work with either knowledge
source. The KV-MemNN performs QA by first storing facts in a key-value structured memory before reasoning on them in order to predict an answer.
The memory is designed so that the model learns to use keys to address relevant memories with respect to the question, whose corresponding values are subsequently
returned.

Model Description

In KV-MemNNs we define the memory slots as pairs of vectors $$(k1; v1) : : : ;(kM; vM)$$ and denote the question $$x$$.

